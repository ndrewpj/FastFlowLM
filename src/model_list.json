{
    "model_path": "flm/models",
    "models": {
        "llama3.2": {
            "1b": {
                "name": "Llama-3.2-1B-NPU2",
                "url": "https://huggingface.co/FastFlowLM/Llama-3.2-1B-NPU2",
                "modified_at": "2025-05-30T00:00:00Z",
                "size": 1000000000,
                "default_context_length": 131072,
                "details": {
                    "format": "NPU2",
                    "family": "llama",
                    "think": false,
                    "parameter_size": "1B",
                    "quantization_level": "AWQ-asym-uint4-g32"
                }
            },
            "3b": {
                "name": "Llama-3.2-3B-NPU2",
                "url": "https://huggingface.co/FastFlowLM/Llama-3.2-3B-NPU2",
                "modified_at": "2025-05-30T00:00:00Z",
                "size": 3000000000,
                "default_context_length": 65536,
                "details": {
                    "format": "NPU2",
                    "family": "llama",
                    "think": false,
                    "parameter_size": "3B",
                    "quantization_level": "AWQ-asym-uint4-g32"
                }
            }
        },
        "llama3.1": {
            "8b": {
                "name": "Llama-3.1-8B-NPU2",
                "url": "https://huggingface.co/FastFlowLM/Llama-3.1-8B-NPU2",
                "modified_at": "2025-05-30T00:00:00Z",
                "size": 8000000000,
                "default_context_length": 32768,
                "details": {
                    "format": "NPU2",
                    "family": "llama",
                    "think": false,
                    "parameter_size": "8B",
                    "quantization_level": "AWQ-asym-uint4-g32"
                }
            }
        },
        "deepseek": {
            "8b": {
                "name": "Deepseek-R1-Distill-Llama-8B-NPU2",
                "url": "https://huggingface.co/FastFlowLM/Deepseek-R1-Distill-Llama-8B-NPU2",
                "modified_at": "2025-05-30T00:00:00Z",
                "size": 8000000000,
                "default_context_length": 32768,
                "details": {
                    "format": "NPU2",
                    "family": "llama",
                    "think": true,
                    "parameter_size": "8B",
                    "quantization_level": "AWQ-asym-uint4-g32"
                }
            }
        },
        "qwen3": {
            "0.6b": {
                "name": "Qwen3-0.6B-NPU2",
                "url": "https://huggingface.co/FastFlowLM/Qwen3-0.6B-NPU2",
                "modified_at": "2025-05-30T00:00:00Z",
                "size": 600000000,
                "default_context_length": 32768,
                "details": {
                    "format": "NPU2",
                    "family": "qwen",
                    "think": true,
                    "think_toggleable": true,
                    "parameter_size": "0.6B",
                    "quantization_level": "AWQ-asym-uint4-g32"
                }
            },
            "1.7b": {
                "name": "Qwen3-1.7B-NPU2",
                "url": "https://huggingface.co/FastFlowLM/Qwen3-1.7B-NPU2",
                "modified_at": "2025-05-30T00:00:00Z",
                "size": 1700000000,
                "default_context_length": 32768,
                "details": {
                    "format": "NPU2",
                    "family": "qwen",
                    "think": true,
                    "think_toggleable": true,
                    "parameter_size": "1.7B",
                    "quantization_level": "AWQ-asym-uint4-g32"
                }
            },
            "4b": {
                "name": "Qwen3-4B-NPU2",
                "url": "https://huggingface.co/FastFlowLM/Qwen3-4B-NPU2",
                "modified_at": "2025-05-30T00:00:00Z",
                "size": 4000000000,
                "default_context_length": 32768,
                "details": {
                    "format": "NPU2",
                    "family": "qwen",
                    "think": true,
                    "think_toggleable": true,
                    "parameter_size": "4B",
                    "quantization_level": "AWQ-asym-uint4-g32"
                }
            },
            "8b": {
                "name": "Qwen3-8B-NPU2",
                "url": "https://huggingface.co/FastFlowLM/Qwen3-8B-NPU2",
                "modified_at": "2025-05-30T00:00:00Z",
                "size": 8000000000,
                "default_context_length": 40960,
                "details": {
                    "format": "NPU2",
                    "family": "qwen",
                    "think": true,
                    "think_toggleable": true,
                    "parameter_size": "8B",
                    "quantization_level": "AWQ-asym-uint4-g32"
                }
            }
        }
    }

}
