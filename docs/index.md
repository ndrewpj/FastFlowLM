---
title: Overview
nav_order: 0
has_children: false
---

# ğŸ§  FastFlowLM

**NPU-only runtime for local LLMs**  
Fast, power-efficient, and 100% offline.

---

## ğŸ§ª Test Drive (Remote Demo)

ğŸš€ Skip the setup â€” experience FastFlowLM instantly on a live AMD Ryzenâ„¢ AI 5 340 NPU with 32â€¯GB memory:

ğŸŒ **Launch Now**: [https://open-webui.testdrive-fastflowlm.com/](https://open-webui.testdrive-fastflowlm.com/)  
ğŸ” **Login**: `guest@flm.npu`  
ğŸ”‘ **Password**: `0000`

> Real-time demo powered by **FastFlowLM + Open WebUI** â€” no downloads, no installs.  
> Upload your own `.txt` files to test extended context prompts.  
> Try three optimized LLaMA models: `llama3.2:1B`, `llama3.2:3B`, and `llama3.1:8B` â€” all accelerated on NPU.

ğŸ“ *Note: Large prompts (30k+ tokens) may take a few seconds longer on the 8B model â€” but it works.*

---

## ğŸ“š Sections

### ğŸš€ [Installation](install.md)
Quick 5â€‘minute setup guide for Windows.

### ğŸ› ï¸ [Instructions](instructions/index.md)
Run FastFlowLM using the CLI (interactive mode) or local server mode.

### ğŸ“Š [Benchmarks](benchmarks/index.md)
Real-time performance comparisons vs AMDâ€™s official stack and other tools.

### ğŸ§© [Models](models/index.md)
Supported models, quantization formats, and compatibility details.
